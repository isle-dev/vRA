{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from src.vRA import RaLLM\n",
    "from src.llm_coder import deductive_coding\n",
    "from utils.krippendorff_alpha import krippendorff\n",
    "from openai import OpenAI\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data and codebook from CSV files\n",
    "data = pd.read_csv(\"./data/data_example.csv\")\n",
    "codebook = pd.read_csv(\"./data/codebook_example.csv\")\n",
    "model = 'gpt-3.5-turbo'\n",
    "#number of in-context examples\n",
    "number_of_example = 5\n",
    "#including context column in example data\n",
    "context = True\n",
    "#if NA label if none of the code applies\n",
    "na_label = False\n",
    "#language setting, 'eng', 'ch', 'fr'\n",
    "language = 'eng'\n",
    "#for majority voting machienism. the number indicates the number of voters.\n",
    "voter = 1\n",
    "#for Chain-of-thought \n",
    "cot = False\n",
    "#For Open AI batch API\n",
    "#https://platform.openai.com/docs/guides/batch/overview\n",
    "batch = False\n",
    "api_key = \"$LLM_API_KEY\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For non-open-ai-models\n",
    "client = OpenAI(\n",
    "    api_key = \"$MOONSHOT_API_KEY\",\n",
    "    base_url = \"https://api.moonshot.cn/v1\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For open-ai-models\n",
    "client = OpenAI(\n",
    "    api_key = api_key\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results, code_set = deductive_coding(data, codebook, codebook_format = 'codebook', number_of_example = number_of_example, context = context, na_label = na_label, language = language, model = model,voter = voter, cot = cot, client = client, batch = batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For verification\n",
    "print(\"Cohen's Kappa: %.3f\" %RaLLM.cohens_kappa_measure(data['code'].astype(str), data['results']))\n",
    "print(\"Krippendorff's Alpha: %.3f\" %RaLLM.krippendorff_alpha_measure(data['code'].astype(str), data['results'],code_set))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output Data\n",
    "results.to_csv(\"data_example_output.csv\", encoding=\"utf_8_sig\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For batch processing\n",
    "# https://platform.openai.com/docs/guides/batch/overview\n",
    "batch_name = 'batch_input'\n",
    "with open('./results/'+batch_name+'.jsonl', 'w') as file:\n",
    "    for item in results:\n",
    "        json_line = json.dumps(item)\n",
    "        file.write(json_line + '\\n')\n",
    "client = OpenAI(api_key = api_key)\n",
    "batch_description = 'batch_coding'\n",
    "batch_input_file = client.files.create(\n",
    "  file=open('./results/'+batch_name+'.jsonl', \"rb\"),\n",
    "  purpose=\"batch\"\n",
    ")\n",
    "\n",
    "batch_input_file_id = batch_input_file.id\n",
    "\n",
    "batch_meta = client.batches.create(\n",
    "    input_file_id=batch_input_file_id,\n",
    "    endpoint=\"/v1/chat/completions\",\n",
    "    completion_window=\"24h\",\n",
    "    metadata={\n",
    "      \"description\": batch_description\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing batch results\n",
    "\n",
    "# Load the JSONL file\n",
    "file_path = 'path/to/results/jsonl'\n",
    "\n",
    "# Read the JSONL file into a list of dictionaries\n",
    "with open(file_path, 'r') as file:\n",
    "    data_source = [json.loads(line) for line in file]\n",
    "\n",
    "# Extract the content and custom_id from each dictionary with the correct path\n",
    "extracted_data = [\n",
    "    {\n",
    "        'custom_id': item['custom_id'], \n",
    "        'content': item['response']['body']['choices'][0]['message']['content']\n",
    "    } \n",
    "    for item in data_source\n",
    "]\n",
    "extracted_data = pd.DataFrame(extracted_data)\n",
    "results = RaLLM.code_clean(extracted_data['content'],code_set)\n",
    "# Convert to a DataFrame\n",
    "data['results'] = pd.Series(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output Data\n",
    "data.to_csv(\"data_example_output.csv\", encoding=\"utf_8_sig\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vRA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
